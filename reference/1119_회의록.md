### 매스프레소에 물어볼 것

Q. 검증 단계에서 name column은 주어지지 않는 게 맞습니까? name이랑 subtitle을 Training feature로만 사용이 가능한 거죠?



Q. 검증 과정에서 input, output이 어떻게 되는지? Input Data type은 어떤 걸까요? 무슨 환경에서 돌아가는 거지? Dockerfile에다가 적어야 하는 건지? GPU랑 running time 제한이 있는지?



### BERT에 대해서

ㅇ수학 기호들이 많잖나. KorQuad는 그냥 한글 텍스트. 수학 기호들을 unknown token으로 처리를 하면 어떻게 하나? -> Fine-tune으로 이를 해결하는 과정이 필요하면 될 것 같은데 어렵다ㅠ 

Tokenizer에다가 단어를 추가할 수 있나?

[관련 BERT 깃헙 이슈](https://github.com/google-research/bert/issues/396)

```
A test is in progress by fine-tuning the CoLA task on run_classifier.py from the existing multilingual model. However, I feel a lack of a dictionary of existing words and want to use a BERT model with pre-trained weight by adding words to vocab.txt. However, modifications to the vocab.txt and vert_config.json files do not match the shape stored in the initial bert_model.ckpt.
```

[별도 학습된 토크나이저 사용 #12](https://github.com/SKTBrain/KoBERT/issues/12)

네 당연히 에러가 납니다. BERT 네트워크 아키텍를 보시면 네트워크 파라메터랑 vocabulary가 하나의 pair라는걸 아실 수 있을겁니다. 네트워크 앞부분 token id embedding만 보더라도 토큰이 달라지면 다른 값을 가져야 된다는걸 아실겁니다.

[multi label text classification #33](https://github.com/SKTBrain/KoBERT/issues/33)

### 처리 작업에 대해서

수학기호 + 한글로 나눠서 train을 시키는 것

* 한글: 연립방정식, 이차방정식 ... 
  * Score 1 yielded from Word2vec, TFIDF. 
  * 아니면 한글 파트를 번역하는 건 어떤가?
* 수학 수식: `MATH NOTATIONS` 
  * Score 2 yielded from BERT

Word2vec을 돌려보면서 느낀 게, 한 Question 문장 안에 정보가 몇 개 없다 ㅠㅠ 길어봐야 두 문장이니까. 개인적으로 BERT나 DL 모델 쓸 때 학습이 제대로 되려나? BERT에서 pretrained set이 저희가 쓰는 math notation이 섞여있는 데이터셋이랑 상이하니까.

* [BERT로 수학문제 풀기](https://www.semanticscholar.org/paper/KoTAB%3A-Korean-Template-Based-Arithmetic-Solver-with-Ki-Lee/67cc3898aa3e009a95df849464c0e3ba814ad294/figure/0)
* [Math Word Problem에 적용된 Transformers](https://colab.research.google.com/drive/1Zi9FOwcO_i-4FDQQGgMMfcZxZISpJNMT#scrollTo=e8XCNkxP8pKA)

### seq2seq

classification에 사용하긴 하

### CNN

Word2vec embedded 벡터를 CNN에다가 돌려서 classification을 하는 걸 본 적이 있다. 이게 더 task에 적합하지 않ㅇ

* [Deep Mind Mathematics Dataset](https://github.com/deepmind/mathematics_dataset)은 사용 가능할 듯. 그러나 notation 방식이 우리 데이터셋이랑 상이함(**가 아니라 ^로 제곱을 표시한다든지). 나머지는 대부분 Math Word Problem set이라서 무쓸모.

## 향후 방향

* 지환: 

  * **기호의 의미를 정확한 벡터를 구하는 게 중요하다고 생각함.** 기호가 ^나 <가 혼용되는 경우가 있기 때문에, 일일이 처리를 해줄 생각이다. 수학 식을 찾아볼 수 있는 걸 찾아봐서, Permutation, Combination처리할 수 있듯이 처리를 하고. 
  * 한글이랑 기호 분리하는 것 괜찮은 것 같아서 그거 진행할 생각
  * Word2vec 모델을 hyperparameter을 고치니까 40%까지 나왔다. **그리고 틀리는 경우는 한 챕터 차이로 틀리고는 했다.** 
  * 인위적으로 구분을 잘 할 수 있게끔 feature을 넣어주면 좋지 않을까? Ex: 상용로그랑 밑이 다른 로그가 다른 중단원으로 잡힌다 치면, 이걸 캐치해서 feature을 쓸 수 있도록 추가하겠다.

* 영진

  * Preprocessing
    * 혼용되는 경우 찾거나 아니면 기호처리
    * ` {Sentence}` 걸러낸 다음에 나누기
    * **Deep mind dataset이랑 notation 통일하는 방향**

* 건욱

  * BERT, Transformers 모델 공부해야지

* 정윤

  * CNN이 multi-class가 안 되는 것 같다 ㅠㅠ

  * 데이터셋을 늘리는 게 좋지 않을까 생각을 했다. 근데 수학문제는 힘들 것 같음.

  * ~~데이터셋을 만들어보자⭐️ 구글 이미지를 OCR을 해봤는데, 이미지가 길어서 처리하기가 힘들 듯 ㅠㅠ. 일단 보류~

    ```
    그림과 같이 △A가 직각인 직각삼각형 ABC에서 AB-3.
    AC=4이다. 꼭킷점 A에서 빗변에 내린 수선의 밭유 D라 하
    자. LBAD= 4r일 때, sinr 이 값은?
    ```

  * 만약 BERmodel 성능이 더 나오지 않는 경우, dataset을 추가하겠다. 

