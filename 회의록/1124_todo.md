# 1124_summary

### Modeling

- [x] [우리 팀 Bert 코드](https://drive.google.com/drive/u/2/folders/11j9f5CHQQ3Rv6Wen52ADFtixHLvybKgt)
  - [x] ID: [ybigtavision@gmail.com](mailto:ybigtavision@gmail.com)
  - [x] PW: ybigta!best!
- [x] KoELECTRA 참고 자료들
  - [x] [Koelectra base-v3 epoch 20으로 돌려서 제출했는데 결과가 좋게 꽤 좋게 나왔어요!ㅎㅎ 전처리 수정해야 되는 부분 있는데 일단 안 고치고 돌려서 수정하고 epoch도 늘리면 점수 더 올릴 수도 있을 것 같아요...!](https://github.com/monologg/KoELECTRA)
  - [x] [Fine Tuning Transformer for MultiClass Text Classification](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb)
- [ ] BERT 참고 자료들
  - [ ] [naver_review_classifications_pytorch_kobert](https://colab.research.google.com/github/SKTBrain/KoBERT/blob/master/scripts/NSMC/naver_review_classifications_pytorch_kobert.ipynb#scrollTo=qAKJvJGY5z1D)
  - [ ] [KoBERT-KorQUAD](https://github.com/monologg/KoBERT-KorQuAD)
  - [ ] [Multi-Label, Multi-Class Text Classification with BERT, Transformer and Keras](https://link.medium.com/x40Sa1aCBbb)
  - [ ] [당근마켓 BERT로 게시글 필터링하기](https://medium.com/daangn/딥러닝으로-동네생활-게시글-필터링하기-263cfe4bc58d)
  - [ ] [KOBERT Score](https://github.com/lovit/KoBERTScore)
- [ ] 불균등한 데이터셋 해결방법
  - [ ] Prediction할 때 weight을 곱해주는 거 어때요? training dataset이 게시물의 그림처럼 불균등하고, hidden dataset이 같은 분포를 따른다고 했죠… 즉 training dataset의 분포 비율 그대로를 weight로 곱해주면 더 정확하지 않을까요 ㅎㅎ
  - [ ] [Training 할 때 loss를 계산할때 weight를 줘서 하는 방식으로 진행. cross entropy에 weight를 줘서 한번 해보자!](https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab)
- [ ] BERT 모델에서는 tokenized된 결과를 확인해볼 수 있는 방법이 있을까요?? math word 처리 부분만 하고, data_preprocessed.csv, data_josa_removed.csv 등 기존에 tokenized된 결과는 이용하지 않는 것 같은데, tfidf / word2vec에서는 잘 예측하지만 BERT에서만 엉뚱하게 예측하는 케이스를 어떻게 해석해야 하는지 궁금합니다!!

### Evaluation Dataset Preprocessing

- [ ] evaluation dataset을 기반으로 Preprocess module for Deep Learning NLP 만들기.
  - [ ] evaluation dataset: "다음 중 옳지 않은 걸 고르시오"
  - [ ] evaluation dataset: `</span>`
- [ ] 혹시 valid set을 사용하시면 valid set를 예측한 label 을 꼭 올려주세요. valid set 중 어떤 문제를 못 맞췄는지 살펴보고 모델을 보완하기 위한 EDA 및 FE를 진행할 계획입니다.


### Training Dataset Preprocessing

![img_diagram](image-20201124084443858.png)

- [ ] **지금 Deep NLP 모델들이 성능이 잘 나오는 것 같아 Preprocess module for Deep NLP 만들어보려고 합니다.** 
  - 그런데 저희가 KoBERT나 KoELECTRA 사용하는데, 이전에 combination이나 permutation 등으로 용어를 바꿔준 부분들을 그럼 순열, 조합 등의 한글로 바꿔 주는 게 나을까요? 아님 그대로 영어 단어로 바꿔 주는 게 나을까요? KoBERT wordpiece에서 영어가 어떻게 처리되는지 모르겠어서요.
  - <>는 txt로 정리를 했지만, ()랑 ^의 중복처리는 아직임. 해야 한다. 이를 Evaluation dataset에 적용
  - `{::}`는 함수식 내 분수를 표현하는 기호. 없애는 것보다 따로 처리해주면 성능이 올라갈까?
  - `sin^`, `cos^`, `tan^` 를 따로 분류하면?
    - ^은 제곱을 의미함.
  - 곱하기 기호가 `x` 문자로 표현되는 경우가 있는 것 같다. (tan1˚xxtan2˚xxcdotsxxtan88˚xxtan89˚=c, Mxxm 등) -> `xx`로 분리되고 있음
    - **xx와 *는 곱하기 noation인데, 이걸 통일시켜줘야 함.**
    - cdots는 continous dots
  - A_1 P_(n-1) 아래첨자 표기법도 Combination, Permutation 처럼 하나로 인식하면 좋을 것 같다. (A, _, 1 로 분리되어 인식되고 있음)
  - `|` 는 절댓값일수도, 조건 bar 일수도(정의역, 치역) -> 물론, '정의역', '치역'이라는 단어로 분리되긴 할 듯.
  - `oo` infinity 기호 -> `oo`로 잘 인식하고 있음
  - `sum`도 math_terms에 -> ex) `lim_(n->oo)1/nsum_(k=1)^(n-1)1/S_k` -> 'lim', '_', '(', 'n', '->', 'oo', ')', '1', '/', 'ns', 'um', '_', '(', 'k', '=', '1', ')', '^', '(', 'n', '-1', ')', '1', '/', 'S', '_', 'k' 로 인식되고 있음. `ns와 um으로 분리되어 인식되고 있음`
  - `squareABCD`가 하나로 인식되고 있음(data 개수 2개) -> 큰 상관은 없을 듯하다
  - 의미중복 ABCD: 사각형? 정사면체? / () : 점? 좌표? / | : 정의역치역? 절댓값?

### Training Dataset Augmentation
- [ ] Nlp data augmentation: 데이터셋 100개 미만 챕터: H1S2-01, H1S1-01, H1S1-06, HSTA-04, H1S1-03, HSTA-01, HSTA-02, H1S1-09, HSU1-11
  - [ ] https://neptune.ai/blog/data-augmentation-nlp
  - [ ] https://inahjeon.github.io/data-augmentation-in-nlp/
  - [ ] https://catsirup.github.io/ai/2020/04/21/nlp_data_argumentation.html
- [ ] **[Deep Mind's Mathematical Q&A Pairs](https://github.com/deepmind/mathematics_dataset)**과의 notation 통일
  - [ ] [Deep mind dataset training 활용 사례](https://github.com/mandubian/pytorch_math_dataset)
  - [ ] [Deep mind 논문 2019](https://github.com/andrewschreiber/hs-math-nlp)
  - [ ] [Automatic Generation of Headlines for Online Math Questions](https://github.com/yuankepku/MathSum)

