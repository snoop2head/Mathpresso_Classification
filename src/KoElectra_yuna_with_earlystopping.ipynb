{"nbformat":4,"nbformat_minor":2,"metadata":{"accelerator":"GPU","colab":{"name":"KoElectra_yuna_with_earlystopping.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","execution_count":null,"source":["import os\n","from getpass import getpass\n","import urllib\n","\n","username = \"sopogen\" #NOT EMAIL!\n","repo_owner_name = \"YooGunWook\"\n","repo_name = \"MATHPRESSO_NLP_Project\"\n","password = getpass('Password: ')\n","password = urllib.parse.quote(password) # your password is converted into url format\n","\n","# !git clone https://username:password@github.com/username/repository.git\n","clone_command = 'git clone https://{0}:{1}@github.com/{2}/{3}.git'.format(username, password, repo_owner_name, repo_name)\n","\n","os.system(clone_command) # commence\n","clone_command, password = \"\", \"\" # removing the password from the variable"],"outputs":[{"output_type":"stream","name":"stdout","text":["Password: ··········\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCa-uo_kK_Nz","executionInfo":{"status":"ok","timestamp":1606495646180,"user_tz":-540,"elapsed":13127,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"3f78a96a-fa73-415d-f1a3-3c8e0c1317eb"}},{"cell_type":"code","execution_count":null,"source":["!ls"],"outputs":[{"output_type":"stream","name":"stdout","text":["MATHPRESSO_NLP_Project\tsample_data\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWvrnOkOP1n7","executionInfo":{"status":"ok","timestamp":1606495646181,"user_tz":-540,"elapsed":12424,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"065e66ff-867d-4586-d1ec-a9dfcc25490c"}},{"cell_type":"code","execution_count":null,"source":["%cd MATHPRESSO_NLP_Project/"],"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MATHPRESSO_NLP_Project\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbVhJVRSP4FR","executionInfo":{"status":"ok","timestamp":1606495654292,"user_tz":-540,"elapsed":749,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"02ba0db9-614d-4e71-a4bd-755290dfcad8"}},{"cell_type":"code","execution_count":null,"source":["!git checkout working"],"outputs":[{"output_type":"stream","name":"stdout","text":["Branch 'working' set up to track remote branch 'working' from 'origin'.\n","Switched to a new branch 'working'\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pZ_RFlaQEZm","executionInfo":{"status":"ok","timestamp":1606495655121,"user_tz":-540,"elapsed":1324,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"36ac0613-ade4-4cbf-befc-325af20fdd07"}},{"cell_type":"code","execution_count":null,"source":["!pip install transformers==3.3.1"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==3.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 18.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 16.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 15.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 15.1MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 13.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 13.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 13.9MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 13.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 13.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 174kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 184kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 215kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 225kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 256kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 276kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 296kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 307kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 317kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 337kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 348kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 358kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 368kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 378kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 389kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 409kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 419kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 430kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 440kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 450kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 460kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 471kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 481kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 491kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 501kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 512kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 522kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 542kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 552kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 563kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 573kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 583kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 593kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 604kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 614kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 624kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 634kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 645kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 655kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 675kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 686kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 696kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 706kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 716kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 727kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 737kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 747kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 757kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 768kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 778kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 788kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 798kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 808kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 819kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 829kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 839kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 849kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 860kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 870kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 880kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 890kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 901kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 911kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 921kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 931kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 942kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 952kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 962kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 972kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 983kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 993kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 13.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 13.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 33.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 57.9MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (1.18.5)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 55.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c5338508a4c0bd255ecfab5b027f4f70b44a10c62005e1632335c752f82beb8f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.3.1\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-ZuirDSVOOl","executionInfo":{"status":"ok","timestamp":1606495662159,"user_tz":-540,"elapsed":8143,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"864af1f5-71fb-4302-c6fb-835ae25ecd1b"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AdamW\n","from tqdm import tqdm, tqdm_notebook\n","from transformers import ElectraModel, ElectraTokenizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score"],"outputs":[],"metadata":{"id":"u8T0ekXzVLbV"}},{"cell_type":"code","execution_count":null,"source":["device = torch.device(\"cuda:0\")"],"outputs":[],"metadata":{"id":"yQ9BmQ5FWf1I"}},{"cell_type":"code","execution_count":null,"source":["# pandas 설정: 각 column 별 (혹은 한 cell에서) 출력되는 글자수 제한을 없애기\n","pd.set_option('display.max_colwidth', -1)\n","df = pd.read_csv('./data/몽데이크_Open.csv')"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  \n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b71Jk_5vVLbV","executionInfo":{"status":"ok","timestamp":1606495667040,"user_tz":-540,"elapsed":8159,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"8594a639-ea87-49b3-fa90-2749458032ec"}},{"cell_type":"code","execution_count":null,"source":["# qtid값 체크\n","df['qtid'] = df['qtid'].apply(lambda x: x[0:7])"],"outputs":[],"metadata":{"id":"GR5XlmA5VLbW"}},{"cell_type":"code","execution_count":null,"source":["# text, qtid열만 가져오기\n","df = df[['qplay_question_id', 'text', 'qtid']]\n","df.reset_index(inplace=True, drop=True)"],"outputs":[],"metadata":{"id":"18OOxeuEVLbW"}},{"cell_type":"code","execution_count":null,"source":["# preprocessing \n","from modules.preprocess_for_kobert import preprocess, drop_noise\n","df_preprocessed = preprocess(df, korean=True, space=True)"],"outputs":[],"metadata":{"id":"DTBpWrxG3dnQ"}},{"cell_type":"code","execution_count":null,"source":["# 라벨 인코더 생성\n","from sklearn.preprocessing import LabelEncoder\n","encoder = LabelEncoder()\n","encoder.fit(df_preprocessed['qtid'])\n","df_preprocessed['qtid'] = encoder.transform(df_preprocessed['qtid'])"],"outputs":[],"metadata":{"id":"Nc1_VBCvEZnE"}},{"cell_type":"code","execution_count":null,"source":["USE_VALID = input('Use valid set? (y/n)')\n","if USE_VALID=='y': \n","  print('Use validation set')\n","  # train, validset 분리할 경우 사용\n","  train_dataset, valid_dataset = train_test_split(df_preprocessed, \n","                                                  stratify=df_preprocessed['qtid'])\n","  valid_dataset = valid_dataset.reset_index(drop=True)\n","  \n","  train_dataset = drop_noise(train_dataset)\n","  train_dataset = train_dataset.reset_index(drop=True)\n","elif USE_VALID=='n':\n","  print('Do not use validation set')\n","  # trainset만 사용할 경우 (validset 사용 x)\n","  train_dataset = df_preprocessed.copy()\n","  train_dataset = drop_noise(train_dataset)\n","  train_dataset = train_dataset.reset_index(drop=True)\n","else:\n","  print('invalid input!')"],"outputs":[{"output_type":"stream","name":"stdout","text":["Use valid set? (y/n)n\n","Do not use validation set\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hdw0ENd9BPMC","executionInfo":{"status":"ok","timestamp":1606495700192,"user_tz":-540,"elapsed":3675,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"7195e2cf-e228-4995-dd84-5c2679ef0777"}},{"cell_type":"code","execution_count":null,"source":["# 하이퍼파라미터 설정\n","MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 50\n","LEARNING_RATE = 1e-05"],"outputs":[],"metadata":{"id":"ImW5okVy_DmK"}},{"cell_type":"code","execution_count":null,"source":["# electra tokenizer 불러오기\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"],"outputs":[],"metadata":{"id":"u79qDRcVZ-Vh"}},{"cell_type":"code","execution_count":null,"source":["# electra 데이터셋\n","\n","class ElectraDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        text = str(self.data.text[index])\n","        text= \" \".join(text.split())\n","        inputs = self.tokenizer(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': self.data.qtid[index]\n","        } \n","    \n","    def __len__(self):\n","        return self.len"],"outputs":[],"metadata":{"id":"p0RFcBox_NJa"}},{"cell_type":"code","execution_count":null,"source":["# train 및 valid dataset 생성\n","training_set = ElectraDataset(train_dataset, tokenizer, MAX_LEN)\n","if USE_VALID=='y':\n","  validation_set = ElectraDataset(valid_dataset, tokenizer, MAX_LEN)"],"outputs":[],"metadata":{"id":"E7jrTkaxBnoL"}},{"cell_type":"code","execution_count":null,"source":["# dataloader\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","               'shuffle': False,\n","               'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","\n","if USE_VALID=='y':\n","  validation_loader = DataLoader(validation_set, **test_params)"],"outputs":[],"metadata":{"id":"XLYdiJTxC4Fd"}},{"cell_type":"code","execution_count":null,"source":["# electra classification model 정의\n","\n","class ElectraModelClass(torch.nn.Module):\n","    def __init__(self):\n","        super(ElectraModelClass, self).__init__()\n","        self.l1 = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\").to(device)\n","        self.pre_classifier = torch.nn.Linear(768, 768)  # small model 사용 시 변경 256\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 592)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"outputs":[],"metadata":{"id":"1CfG7QQZC4YH"}},{"cell_type":"code","execution_count":null,"source":["model = ElectraModelClass()\n","model.to(device)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["ElectraModelClass(\n","  (l1): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":28}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rj3kX5ADHWr","executionInfo":{"status":"ok","timestamp":1606495709953,"user_tz":-540,"elapsed":4702,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"e85d0633-3174-44b6-dd9e-05005e3593f1"}},{"cell_type":"code","execution_count":null,"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"outputs":[],"metadata":{"id":"O0u7lV2zDL_s"}},{"cell_type":"code","execution_count":null,"source":["# Function to calcuate the accuracy of the model\n","\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"],"outputs":[],"metadata":{"id":"5trt00l2Dc3R"}},{"cell_type":"code","execution_count":null,"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"outputs":[],"metadata":{"id":"9VWiWPvPWfx6"}},{"cell_type":"code","execution_count":null,"source":["early_stopping = EarlyStopping(patience=10, verbose=True)"],"outputs":[],"metadata":{"id":"R7LFf0neqeWe"}},{"cell_type":"code","execution_count":null,"source":["# Defining the training function on the 80% of the dataset for tuning the distilbert model\n","\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    epoch_result = []\n","    epoch_target = []\n","    model.train()\n","    print(f\"Current Epoch: {epoch+1}\")\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","        epoch_result.append(big_idx.cpu().numpy())\n","        epoch_target.append(targets.cpu().numpy())\n","        \n","        if _%5000==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 5000 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    \n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return epoch_result, epoch_accu, epoch_loss, epoch_target"],"outputs":[],"metadata":{"id":"tP15E-RSDdpB"}},{"cell_type":"code","execution_count":null,"source":["# validset 사용할 때 prediction\n","def valid_pred(model, testing_loader, usage='pred'):\n","    model.eval()\n","    n_correct = 0; n_wrong = 0; total = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    predict = []\n","    answer = []\n","    epoch_result = []\n","    epoch_target = []\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask)\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","            epoch_result.append(big_idx.cpu().numpy())\n","            epoch_target.append(targets.cpu().numpy())\n","            \n","            for i in range(VALID_BATCH_SIZE):\n","              try:\n","                predict.append(big_idx[i])\n","                answer.append(targets[i])\n","              except: pass\n","            \n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _%5000==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    if usage == 'eval':\n","        return epoch_result, epoch_accu, epoch_loss, epoch_target\n","    else:\n","        return predict,answer"],"outputs":[],"metadata":{"id":"GSlnt0B7Div6"}},{"cell_type":"code","execution_count":null,"source":["train_accuracy_flow = []\n","train_loss_flow = []\n","train_f1_flow = []\n","valid_accuracy_flow = []\n","valid_loss_flow = []\n","valid_f1_flow = []\n","\n","for epoch in range(EPOCHS):\n","    epoch_result, epoch_accu, epoch_loss, epoch_target = train(epoch)\n","    temp = epoch_result[0]\n","    for i in range(1, len(epoch_result)):\n","        temp = np.concatenate((temp, epoch_result[i]), axis=None)\n","    epoch_result = temp.tolist()\n","    temp = epoch_target[0]\n","    for i in range(1, len(epoch_target)):\n","        temp = np.concatenate((temp, epoch_target[i]), axis=None)\n","    epoch_target = temp.tolist()\n","    train_f1 = f1_score(epoch_target, epoch_result, average='weighted')\n","    train_accuracy_flow.append(epoch_accu)\n","    train_loss_flow.append(epoch_loss)\n","    train_f1_flow.append(train_f1)\n","\n","    if USE_VALID=='y':\n","    \n","      epoch_result, epoch_accu, epoch_loss, epoch_target = valid_pred(model, validation_loader, usage='eval')\n","      temp = epoch_result[0]\n","      for i in range(1, len(epoch_result)):\n","          temp = np.concatenate((temp, epoch_result[i]), axis=None)\n","      epoch_result = temp.tolist()\n","      temp = epoch_target[0]\n","      for i in range(1, len(epoch_target)):\n","          temp = np.concatenate((temp, epoch_target[i]), axis=None)\n","      epoch_target = temp.tolist()\n","      valid_f1 = f1_score(epoch_target, epoch_result, average='weighted')\n","      valid_accuracy_flow.append(epoch_accu)\n","      valid_loss_flow.append(epoch_loss)\n","      valid_f1_flow.append(valid_f1)\n","\n","      early_stopping(epoch_loss, model)\n","      if early_stopping.early_stop:\n","          print('Early Stop!!!!')\n","          break"],"outputs":[{"output_type":"stream","name":"stdout","text":["Current Epoch: 1\n","Training Loss per 5000 steps: 3.6453189849853516\n","Training Accuracy per 5000 steps: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Training Loss Epoch: 3.093563126554753\n","Training Accuracy Epoch: 22.400897531787585\n","Current Epoch: 2\n","Training Loss per 5000 steps: 2.199646472930908\n","Training Accuracy per 5000 steps: 75.0\n","Training Loss Epoch: 1.9367322850200608\n","Training Accuracy Epoch: 53.889304412864625\n","Current Epoch: 3\n","Training Loss per 5000 steps: 1.2339359521865845\n","Training Accuracy per 5000 steps: 50.0\n","Training Loss Epoch: 1.170720798784704\n","Training Accuracy Epoch: 73.31712789827974\n","Current Epoch: 4\n","Training Loss per 5000 steps: 0.7757232189178467\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.7316076417043303\n","Training Accuracy Epoch: 83.05908750934928\n","Current Epoch: 5\n","Training Loss per 5000 steps: 0.7030453085899353\n","Training Accuracy per 5000 steps: 75.0\n","Training Loss Epoch: 0.47523550437895684\n","Training Accuracy Epoch: 88.7247569184742\n","Current Epoch: 6\n","Training Loss per 5000 steps: 0.17924295365810394\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.324994824284781\n","Training Accuracy Epoch: 91.9035153328347\n","Current Epoch: 7\n","Training Loss per 5000 steps: 0.07022863626480103\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.2505797102334077\n","Training Accuracy Epoch: 93.45549738219896\n","Current Epoch: 8\n","Training Loss per 5000 steps: 0.04356298968195915\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.18206733004897052\n","Training Accuracy Epoch: 95.66192969334331\n","Current Epoch: 9\n","Training Loss per 5000 steps: 0.09854041039943695\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.1441303654420611\n","Training Accuracy Epoch: 96.2789827973074\n","Current Epoch: 10\n","Training Loss per 5000 steps: 0.042000528424978256\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.11932353588363062\n","Training Accuracy Epoch: 96.8773373223635\n","Current Epoch: 11\n","Training Loss per 5000 steps: 0.01936563104391098\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.09385631677730144\n","Training Accuracy Epoch: 97.5130890052356\n","Current Epoch: 12\n","Training Loss per 5000 steps: 0.3524875342845917\n","Training Accuracy per 5000 steps: 75.0\n","Training Loss Epoch: 0.07982011551853122\n","Training Accuracy Epoch: 97.94315632011967\n","Current Epoch: 13\n","Training Loss per 5000 steps: 0.4580303430557251\n","Training Accuracy per 5000 steps: 75.0\n","Training Loss Epoch: 0.06699608426548752\n","Training Accuracy Epoch: 98.20493642483171\n","Current Epoch: 14\n","Training Loss per 5000 steps: 0.019330782815814018\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.07375407897903484\n","Training Accuracy Epoch: 98.1488406881077\n","Current Epoch: 15\n","Training Loss per 5000 steps: 0.019002310931682587\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.06464902819001946\n","Training Accuracy Epoch: 98.35452505609574\n","Current Epoch: 16\n","Training Loss per 5000 steps: 0.022887321189045906\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.05001145443071388\n","Training Accuracy Epoch: 98.7471952131638\n","Current Epoch: 17\n","Training Loss per 5000 steps: 0.36592188477516174\n","Training Accuracy per 5000 steps: 75.0\n","Training Loss Epoch: 0.04028430420636473\n","Training Accuracy Epoch: 99.00897531787584\n","Current Epoch: 18\n","Training Loss per 5000 steps: 0.021278684958815575\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.05158036812323528\n","Training Accuracy Epoch: 98.61630516080778\n","Current Epoch: 19\n","Training Loss per 5000 steps: 0.003543731290847063\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.04176098268116715\n","Training Accuracy Epoch: 98.89678384442783\n","Current Epoch: 20\n","Training Loss per 5000 steps: 0.004943886771798134\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.04884914641880494\n","Training Accuracy Epoch: 98.85938668661181\n","Current Epoch: 21\n","Training Loss per 5000 steps: 0.003516413504257798\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.03436416832683329\n","Training Accuracy Epoch: 99.19596110695588\n","Current Epoch: 22\n","Training Loss per 5000 steps: 0.002692358335480094\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.04303763927593193\n","Training Accuracy Epoch: 98.82198952879581\n","Current Epoch: 23\n","Training Loss per 5000 steps: 0.006690572947263718\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.03748342060395962\n","Training Accuracy Epoch: 98.99027673896784\n","Current Epoch: 24\n","Training Loss per 5000 steps: 0.004525736439973116\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.03254821109143138\n","Training Accuracy Epoch: 99.25205684367988\n","Current Epoch: 25\n","Training Loss per 5000 steps: 0.00434060487896204\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.029942864408558437\n","Training Accuracy Epoch: 99.15856394913986\n","Current Epoch: 26\n","Training Loss per 5000 steps: 0.003919263370335102\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.03031248851880315\n","Training Accuracy Epoch: 99.25205684367988\n","Current Epoch: 27\n","Training Loss per 5000 steps: 0.00306992931291461\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.02411703036329378\n","Training Accuracy Epoch: 99.19596110695588\n","Current Epoch: 28\n","Training Loss per 5000 steps: 0.011190995573997498\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.029968510330548453\n","Training Accuracy Epoch: 99.13986537023186\n","Current Epoch: 29\n","Training Loss per 5000 steps: 0.0035211914218962193\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.015819157121144723\n","Training Accuracy Epoch: 99.60732984293193\n","Current Epoch: 30\n","Training Loss per 5000 steps: 0.0021110426168888807\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.028408741032082668\n","Training Accuracy Epoch: 99.28945400149588\n","Current Epoch: 31\n","Training Loss per 5000 steps: 0.0005372923915274441\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.023970499307134175\n","Training Accuracy Epoch: 99.43904263275991\n","Current Epoch: 32\n","Training Loss per 5000 steps: 0.0037572653964161873\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.033050909833663905\n","Training Accuracy Epoch: 99.13986537023186\n","Current Epoch: 33\n","Training Loss per 5000 steps: 0.0010453535942360759\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.035274721863050924\n","Training Accuracy Epoch: 99.02767389678384\n","Current Epoch: 34\n","Training Loss per 5000 steps: 0.0012978716986253858\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.02056598453998002\n","Training Accuracy Epoch: 99.53253552729993\n","Current Epoch: 35\n","Training Loss per 5000 steps: 0.0019495186861604452\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.024309063332153866\n","Training Accuracy Epoch: 99.43904263275991\n","Current Epoch: 36\n","Training Loss per 5000 steps: 0.0017537340754643083\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.031735263808764326\n","Training Accuracy Epoch: 99.23335826477188\n","Current Epoch: 37\n","Training Loss per 5000 steps: 0.0025282022543251514\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.02707368497941894\n","Training Accuracy Epoch: 99.28945400149588\n","Current Epoch: 38\n","Training Loss per 5000 steps: 0.001923270057886839\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.013799240419148049\n","Training Accuracy Epoch: 99.64472700074795\n","Current Epoch: 39\n","Training Loss per 5000 steps: 0.0011746203526854515\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.015136130849588137\n","Training Accuracy Epoch: 99.66342557965595\n","Current Epoch: 40\n","Training Loss per 5000 steps: 0.0020016853231936693\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.04497861627110957\n","Training Accuracy Epoch: 98.87808526551981\n","Current Epoch: 41\n","Training Loss per 5000 steps: 0.00280367792584002\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.021765848375181546\n","Training Accuracy Epoch: 99.47643979057591\n","Current Epoch: 42\n","Training Loss per 5000 steps: 0.0006776161026209593\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.019600959155705852\n","Training Accuracy Epoch: 99.4203440538519\n","Current Epoch: 43\n","Training Loss per 5000 steps: 0.004856020677834749\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.011580323235292622\n","Training Accuracy Epoch: 99.70082273747195\n","Current Epoch: 44\n","Training Loss per 5000 steps: 0.0015041034203022718\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.028700378099549596\n","Training Accuracy Epoch: 99.17726252804786\n","Current Epoch: 45\n","Training Loss per 5000 steps: 0.0010414380813017488\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.01749239774454511\n","Training Accuracy Epoch: 99.53253552729993\n","Current Epoch: 46\n","Training Loss per 5000 steps: 0.0027597439475357533\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.015078240728335161\n","Training Accuracy Epoch: 99.56993268511593\n","Current Epoch: 47\n","Training Loss per 5000 steps: 0.0012039269786328077\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.02003791541265884\n","Training Accuracy Epoch: 99.43904263275991\n","Current Epoch: 48\n","Training Loss per 5000 steps: 0.0017572419019415975\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.023391374929523527\n","Training Accuracy Epoch: 99.3642483171279\n","Current Epoch: 49\n","Training Loss per 5000 steps: 0.0004798362497240305\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.012060912927058362\n","Training Accuracy Epoch: 99.62602842183993\n","Current Epoch: 50\n","Training Loss per 5000 steps: 0.0006939137820154428\n","Training Accuracy per 5000 steps: 100.0\n","Training Loss Epoch: 0.011567109139762544\n","Training Accuracy Epoch: 99.68212415856395\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y99ixwmtDgWs","executionInfo":{"status":"ok","timestamp":1606506233776,"user_tz":-540,"elapsed":10517428,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"e6ac04e6-d1db-4026-8063-23689ef1a045"}},{"cell_type":"code","execution_count":null,"source":["plt.figure(figsize=(16, 16), facecolor='white')\n","plt.subplot(311)\n","plt.plot([i for i in range(1, len(train_accuracy_flow) + 1)], train_loss_flow)\n","plt.plot([i for i in range(1, len(valid_loss_flow) + 1)], valid_loss_flow)\n","plt.legend(['train', 'valid'])\n","plt.title('loss')\n","\n","plt.subplot(312)\n","plt.plot([i for i in range(1, len(train_f1_flow) + 1)], train_f1_flow)\n","plt.plot([i for i in range(1, len(valid_f1_flow) + 1)], valid_f1_flow)\n","plt.legend(['train', 'valid'])\n","plt.title('f1')\n","\n","plt.subplot(313)\n","plt.plot([i for i in range(1, len(train_accuracy_flow) + 1)], train_accuracy_flow)\n","plt.plot([i for i in range(1, len(valid_accuracy_flow) + 1)], valid_accuracy_flow)\n","plt.legend(['train', 'valid'])\n","plt.title('accuracy')"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'accuracy')"]},"metadata":{"tags":[]},"execution_count":68},{"output_type":"display_data","data":{"image/png":"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","text/plain":["<Figure size 1152x1152 with 3 Axes>"]},"metadata":{"tags":[]}}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":952},"id":"unFcg9c3p2xK","outputId":"8f18ecd8-ad5a-462e-e14a-06a7fe36fba5"}},{"cell_type":"code","execution_count":null,"source":["'''\n","# train prediction\n","\n","def train_pred(model, testing_loader):\n","    model.eval()\n","    n_correct = 0; n_wrong = 0; total = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    predict = []\n","    answer = []\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask)\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","\n","            \n","            for i in range(TRAIN_BATCH_SIZE):\n","              try:\n","                predict.append(big_idx[i])\n","                answer.append(targets[i])\n","              except: pass\n","            \n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _%5000==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    return predict\n","'''\n"],"outputs":[],"metadata":{"id":"LF0OTM1hnpyM"}},{"cell_type":"code","execution_count":null,"source":["if USE_VALID == 'y':\n","  valid_predictions = valid_pred(model, validation_loader)\n","  valid_pred_list = []\n","  valid_true_list = []\n","  for i in range(len(valid_predictions[0])):\n","    valid_pred_list.append(int(valid_predictions[0][i]))\n","  for i in range(len(valid_predictions[1])):\n","    valid_true_list.append(int(valid_predictions[1][i]))\n","\n","  # valid_result\n","  valid_pred_decode = encoder.inverse_transform(valid_pred_list)\n","  valid_true_decode = encoder.inverse_transform(valid_true_list)\n","  valid_id = []\n","  for i in range(len(valid_dataset)):\n","      valid_id.append(int(valid_dataset.loc[i, 'qplay_question_id']))\n","  \n","  valid_result = pd.DataFrame(valid_id, columns=['qplay_question_id'])\n","  valid_result['predict_category'] = valid_pred_decode\n","  valid_result['true_category'] = valid_true_decode\n","\n","  valid_result"],"outputs":[],"metadata":{"id":"uZj7YpBrGd-e"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"96uacz__RlrW"}},{"cell_type":"code","execution_count":null,"source":["\n","# valid_result\n","valid_pred_encode = encoder.inverse_transform(valid_pred)\n","valid_result = []\n","for i in range(len()):\n","    temp_dic = {}\n","    temp_dic['qplay_question_id'] = int(valid_dataset.loc[i, 'qplay_question_id'])\n","    temp_dic['predict_category'] = valid_pred_encode[i]\n","    valid_result.append(temp_dic)\n","\n","valid_result[0]\n"],"outputs":[],"metadata":{"id":"jeyTfOyReHl6"}},{"cell_type":"code","execution_count":null,"source":["# Saving the files for re-use\n","\n","output_model_file = './pytorch_Koelectra.bin'\n","output_vocab_file = './vocab_Koelectr.bin'\n","\n","model_to_save = model\n","torch.save(model_to_save, output_model_file)\n","tokenizer.save_vocabulary(output_vocab_file)\n","\n","print('All files saved')\n","print('This tutorial is completed')\n"],"outputs":[],"metadata":{"id":"-ISCosv9Ibv6"}},{"cell_type":"code","execution_count":null,"source":["torch.save(model, './pytorch_Koelectra_model.pt')  # 전체 모델 저장\n","torch.save(model.state_dict(), './pytorch_Koelectra_model_state_dict.pt')  # 모델 객체의 state_dict 저장\n","torch.save({\n","    'model': model.state_dict(),\n","    'optimizer': optimizer.state_dict()\n","}, './all.tar')"],"outputs":[],"metadata":{"id":"JdU_wProjp0C"}},{"cell_type":"markdown","source":["# test"],"metadata":{"id":"A6VtVM40OQlm"}},{"cell_type":"code","execution_count":null,"source":["testset = pd.read_csv('./data/hidden_for_inference.csv')\n","\n","test_preprocessed = preprocess(testset, korean=True, space=True)"],"outputs":[],"metadata":{"id":"8R_j2q3COPpn"}},{"cell_type":"code","execution_count":null,"source":["class ElectratestDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        text = str(self.data.text[index])\n","        text= \" \".join(text.split())\n","        inputs = self.tokenizer(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            \n","        } \n","    \n","    def __len__(self):\n","        return self.len"],"outputs":[],"metadata":{"id":"P_aMCM9nwHIp"}},{"cell_type":"code","execution_count":null,"source":["test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': False,\n","                'num_workers': 0\n","                }\n","test_set = ElectratestDataset(test_preprocessed, tokenizer, MAX_LEN)"],"outputs":[],"metadata":{"id":"rrBvsYYgwNiy"}},{"cell_type":"code","execution_count":null,"source":["test_loader = DataLoader(test_set, **test_params)"],"outputs":[],"metadata":{"id":"VjTcx236wnb7"}},{"cell_type":"code","execution_count":null,"source":["def testmodel(model, testing_loader):\n","    model.eval()\n","    predict = []\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask)\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","\n","            for i in range(VALID_BATCH_SIZE):\n","              try:\n","                predict.append(big_idx[i])\n","\n","              except: pass\n","\n","    return predict"],"outputs":[],"metadata":{"id":"A8nXjl63tVi0"}},{"cell_type":"code","execution_count":null,"source":["test_predictions = testmodel(model, test_loader)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"metadata":{"id":"4Lss6sTLtqTu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606524973666,"user_tz":-540,"elapsed":16154,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"4011572a-8869-4d47-eccd-be9217f91713"}},{"cell_type":"code","execution_count":null,"source":["test_pred = []\n","for i in range(len(test_predictions)):\n","  test_pred.append(int(test_predictions[i]))"],"outputs":[],"metadata":{"id":"VTSOj7e_CPxp"}},{"cell_type":"code","execution_count":null,"source":["test_pred_encode = encoder.inverse_transform(test_pred)"],"outputs":[],"metadata":{"id":"s8nInQjYDewn"}},{"cell_type":"code","execution_count":null,"source":["# submission\n","submission = []\n","for i in range(len(testset)):\n","    temp_dic = {}\n","    temp_dic['qplay_question_id'] = int(testset.loc[i, 'qplay_question_id'])\n","    temp_dic['predict_category'] = test_pred_encode[i]\n","    submission.append(temp_dic)\n","\n","submission[0]"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'predict_category': 'H1S1-10', 'qplay_question_id': 3535}"]},"metadata":{"tags":[]},"execution_count":55}],"metadata":{"id":"Rjrqs-AfFvnw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606524973669,"user_tz":-540,"elapsed":7667,"user":{"displayName":"Jiwhan Kim","photoUrl":"","userId":"05438130622648529843"}},"outputId":"7f016d72-e121-454c-9406-c1564075da83"}},{"cell_type":"code","execution_count":null,"source":["submission_df = pd.DataFrame(submission)\n","submission_df.to_csv('koELECTRA_pre_epoch50.csv')"],"outputs":[],"metadata":{"id":"jakwx0yoejDg"}}]}